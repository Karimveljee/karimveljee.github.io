[
  {
    "objectID": "index.html#greetings",
    "href": "index.html#greetings",
    "title": "Karim Veljee",
    "section": "Greetings!",
    "text": "Greetings!\nWelcome to my website. I am pursuing MS in Social Data Analytics from the University of Texas at Dallas.\nPlease contact me at karim.veljee@gmail.com"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a Data Analytics professional with a solid foundation in project management, research, and finance. My career has spanned from managing intricate financial transactions in investment banking to spearheading research projects that impact educational policies. At each turn, I have leveraged my analytical acumen to uncover insights and drive strategic decisions. Whether it’s enhancing data processes in a university setting or managing research budgets in academia, my approach combines meticulous analysis with strategic oversight. I am passionate about using data to solve complex problems and create meaningful change, bridging the gap between numbers and narrative in every project I undertake."
  },
  {
    "objectID": "assignments/assignment1.html",
    "href": "assignments/assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "## Data Visualization\n## Objective: Identify data or model problems using visualization\n## Anscombe (1973) Quartlet\n\ndata(anscombe)  # Load Anscombe's data\nView(anscombe) # View the data\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n## Simple version\nplot(anscombe$x1,anscombe$y1)\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n# Create four model objects\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nsummary(lm3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\nsummary(lm4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nplot(anscombe$x1,anscombe$y1)\nabline(coefficients(lm1))\n\n\n\n\n\n\n\nplot(anscombe$x2,anscombe$y2)\nabline(coefficients(lm2))\n\n\n\n\n\n\n\nplot(anscombe$x3,anscombe$y3)\nabline(coefficients(lm3))\n\n\n\n\n\n\n\nplot(anscombe$x4,anscombe$y4)\nabline(coefficients(lm4))\n\n\n\n\n\n\n\n## Fancy version (per help file)\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] &lt;- as.name(paste0(\"y\", i))\n  ##      ff[[3]] &lt;- as.name(paste0(\"x\", i))\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n# Preparing for the plots\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n\n\npar(op)"
  },
  {
    "objectID": "assignments/assignment1.html#anscombe-1973-quartlet",
    "href": "assignments/assignment1.html#anscombe-1973-quartlet",
    "title": "Assignment 1",
    "section": "",
    "text": "## Data Visualization\n## Objective: Identify data or model problems using visualization\n## Anscombe (1973) Quartlet\n\ndata(anscombe)  # Load Anscombe's data\nView(anscombe) # View the data\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n## Simple version\nplot(anscombe$x1,anscombe$y1)\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n# Create four model objects\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nsummary(lm3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\nsummary(lm4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nplot(anscombe$x1,anscombe$y1)\nabline(coefficients(lm1))\n\n\n\n\n\n\n\nplot(anscombe$x2,anscombe$y2)\nabline(coefficients(lm2))\n\n\n\n\n\n\n\nplot(anscombe$x3,anscombe$y3)\nabline(coefficients(lm3))\n\n\n\n\n\n\n\nplot(anscombe$x4,anscombe$y4)\nabline(coefficients(lm4))\n\n\n\n\n\n\n\n## Fancy version (per help file)\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] &lt;- as.name(paste0(\"y\", i))\n  ##      ff[[3]] &lt;- as.name(paste0(\"x\", i))\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n# Preparing for the plots\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n\n\npar(op)"
  },
  {
    "objectID": "assignments/assignment1.html#generative-art",
    "href": "assignments/assignment1.html#generative-art",
    "title": "Assignment 1",
    "section": "2 Generative Art",
    "text": "2 Generative Art\nKatharina Brunner is a generative artist and data journalist whose GitHub repository on Generative Art is a great resource for anyone looking to get started using the programming language R.\n\nSource: https://aiartists.org/generative-art-design"
  },
  {
    "objectID": "assignments/assignment1.html#fall.r",
    "href": "assignments/assignment1.html#fall.r",
    "title": "Assignment 1",
    "section": "3 Fall.R",
    "text": "3 Fall.R\n\n## Data Visualization\n## Objective: Create graphics with R\n## Title: Fall color\n# Credit: https://fronkonstin.com\n\nlibrary(gsubfn)\n\nWarning: package 'gsubfn' was built under R version 4.3.3\n\n\nLoading required package: proto\n\n\nWarning: package 'proto' was built under R version 4.3.3\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Define elements in plant art\n# Each image corresponds to a different axiom, rules, angle and depth\n\n# Leaf of Fall\n\naxiom=\"X\"\nrules=list(\"X\"=\"F-[[X]+X]+F[+FX]-X\", \"F\"=\"FF\")\nangle=22.5\ndepth=6\n\n\nfor (i in 1:depth) axiom=gsubfn(\".\", rules, axiom)\n\nactions=str_extract_all(axiom, \"\\\\d*\\\\+|\\\\d*\\\\-|F|L|R|\\\\[|\\\\]|\\\\|\") %&gt;% unlist\n\nstatus=data.frame(x=numeric(0), y=numeric(0), alfa=numeric(0))\npoints=data.frame(x1 = 0, y1 = 0, x2 = NA, y2 = NA, alfa=90, depth=1)\n\n\n# Generating data\n# Note: may take a minute or two\n\nfor (action in actions)\n{\n  if (action==\"F\")\n  {\n    x=points[1, \"x1\"]+cos(points[1, \"alfa\"]*(pi/180))\n    y=points[1, \"y1\"]+sin(points[1, \"alfa\"]*(pi/180))\n    points[1,\"x2\"]=x\n    points[1,\"y2\"]=y\n    data.frame(x1 = x, y1 = y, x2 = NA, y2 = NA,\n               alfa=points[1, \"alfa\"],\n               depth=points[1,\"depth\"]) %&gt;% rbind(points)-&gt;points\n  }\n  if (action %in% c(\"+\", \"-\")){\n    alfa=points[1, \"alfa\"]\n    points[1, \"alfa\"]=eval(parse(text=paste0(\"alfa\",action, angle)))\n  }\n  if(action==\"[\"){\n    data.frame(x=points[1, \"x1\"], y=points[1, \"y1\"], alfa=points[1, \"alfa\"]) %&gt;%\n      rbind(status) -&gt; status\n    points[1, \"depth\"]=points[1, \"depth\"]+1\n  }\n\n  if(action==\"]\"){\n    depth=points[1, \"depth\"]\n    points[-1,]-&gt;points\n    data.frame(x1=status[1, \"x\"], y1=status[1, \"y\"], x2=NA, y2=NA,\n               alfa=status[1, \"alfa\"],\n               depth=depth-1) %&gt;%\n      rbind(points) -&gt; points\n    status[-1,]-&gt;status\n  }\n}\n\nggplot() +\n  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2),\n               lineend = \"round\",\n               color=\"coral\",\n               data=na.omit(points)) +\n  coord_fixed(ratio = 1) +\n  theme_void() # No grid nor axes"
  },
  {
    "objectID": "assignments/assignment1.html#critique",
    "href": "assignments/assignment1.html#critique",
    "title": "Assignment 1",
    "section": "4 Critique",
    "text": "4 Critique\n\nK Roeder (1994) DNA Fingerprinting: A Review of the Controversy (with Discussion). Statistical Science, 9(2), 222-278, Figure 9\nThe use of three dimensional rendering for the curves is unnecessary and detracts from the clarity of data. The curves are represented as ribbons, which complicates interpretation without adding value. Displaying multiple curves in a way that ensures they are distinguishable can be challenging. While the use of color would be ideal, employing distinct line styles would effectively differentiate the curves without compromising clarity.\nSource: https://www.semanticscholar.org/paper/DNA-Fingerprinting%3A-A-Review-of-the-Controversy-Roeder/7e66658a3fdb277c86f4f8f606a9c26ff69c9388"
  },
  {
    "objectID": "assignments/assignment2.html",
    "href": "assignments/assignment2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "### Paul Murrell's R examples (selected)\n\n## Start plotting from basics \n# Note the order\nplot(pressure, pch=20)\ntext(150, 600, \n     \"Pressure (mm Hg)\\nversus\\nTemperature (Celsius)\")\n\n\n\n\n\n\n\n#  Examples of standard high-level plots \n#  In each case, extra output is also added using low-level \n#  plotting functions.\n# \n\n# Setting the parameter (3 rows by 2 cols)\npar(mfrow=c(3, 2))\n\n# Scatterplot\n# Note the incremental additions\n\nx &lt;- c(0.5, 2, 4, 8, 12, 16)\ny1 &lt;- c(1, 1.3, 1.9, 3.4, 3.9, 4.8)\ny2 &lt;- c(4, .8, .5, .45, .4, .3)\n\n# Setting label orientation, margins c(bottom, left, top, right) & text size\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) \nplot.new()\nplot.window(range(x), c(0, 6))\nlines(x, y1)\nlines(x, y2)\npoints(x, y1, pch=16, cex=3) \npoints(x, y2, pch=21, bg=\"lightblue\", cex=2)\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(0, 16, 4)) # What is the first number standing for? The first number in the axis() function stands for the side of the plot where the axis is drawn. 1 is the bottom, 2 is the left, 3 is top and 4 is the right side.\naxis(2, at=seq(0, 6, 2))\naxis(4, at=seq(0, 6, 2))\nbox(bty=\"u\")\nmtext(\"Travel Time (s)\", side=1, line=2, cex=0.8)\nmtext(\"Responses per Travel\", side=2, line=2, las=0, cex=0.8)\nmtext(\"Responses per Second\", side=4, line=2, las=0, cex=0.8)\ntext(4, 5, \"Bird 131\")\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n# Histogram\n# Random data\nY &lt;- rnorm(50)\n# Make sure no Y exceed [-3.5, 3.5]\nY[Y &lt; -3.5 | Y &gt; 3.5] &lt;- NA # Selection/set range\nx &lt;- seq(-3.5, 3.5, .1)\ndn &lt;- dnorm(x)\npar(mar=c(4.5, 4.1, 3.1, 0))\nhist(Y, breaks=seq(-3.5, 3.5), ylim=c(0, 0.5), \n     col=\"gray80\", freq=FALSE)\nlines(x, dnorm(x), lwd=2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Barplot\npar(mar=c(2, 3.1, 2, 2.1)) \nmidpts &lt;- barplot(VADeaths, \n                  col=gray(0.1 + seq(1, 9, 2)/11), \n                  names=rep(\"\", 4))\nmtext(sub(\" \", \"\\n\", colnames(VADeaths)),\n      at=midpts, side=1, line=0.5, cex=0.5)\ntext(rep(midpts, each=5), apply(VADeaths, 2, cumsum) - VADeaths/2,\n     VADeaths, \n     col=rep(c(\"white\", \"black\"), times=3:2), \n     cex=0.8)\npar(mar=c(5.1, 4.1, 4.1, 2.1))  \n\n# Boxplot\npar(mar=c(3, 4.1, 2, 0))\nboxplot(len ~ dose, data = ToothGrowth,\n        boxwex = 0.25, at = 1:3 - 0.2,\n        subset= supp == \"VC\", col=\"white\",\n        xlab=\"\",\n        ylab=\"tooth length\", ylim=c(0,35))\nmtext(\"Vitamin C dose (mg)\", side=1, line=2.5, cex=0.8)\nboxplot(len ~ dose, data = ToothGrowth, add = TRUE,\n        boxwex = 0.25, at = 1:3 + 0.2,\n        \n        subset= supp == \"OJ\")\nlegend(1.5, 9, c(\"Ascorbic acid\", \"Orange juice\"), \n       fill = c(\"white\", \"gray\"), \n       bty=\"n\")\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Persp\nx &lt;- seq(-10, 10, length= 30)\ny &lt;- x\nf &lt;- function(x,y) { r &lt;- sqrt(x^2+y^2); 10 * sin(r)/r }\nz &lt;- outer(x, y, f)\nz[is.na(z)] &lt;- 1\n# 0.5 to include z axis label\npar(mar=c(0, 0.5, 0, 0), lwd=0.5)\npersp(x, y, z, theta = 30, phi = 30, \n      expand = 0.5)\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n# Piechart\npar(mar=c(0, 2, 1, 2), xpd=FALSE, cex=0.5)\npie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)\nnames(pie.sales) &lt;- c(\"Blueberry\", \"Cherry\",\n                      \"Apple\", \"Boston Cream\", \"Other\", \"Vanilla\")\npie(pie.sales, col = gray(seq(0.3,1.0,length=6)))"
  },
  {
    "objectID": "assignments/assignment2.html#murrell01.r",
    "href": "assignments/assignment2.html#murrell01.r",
    "title": "Assignment 2",
    "section": "",
    "text": "### Paul Murrell's R examples (selected)\n\n## Start plotting from basics \n# Note the order\nplot(pressure, pch=20)\ntext(150, 600, \n     \"Pressure (mm Hg)\\nversus\\nTemperature (Celsius)\")\n\n\n\n\n\n\n\n#  Examples of standard high-level plots \n#  In each case, extra output is also added using low-level \n#  plotting functions.\n# \n\n# Setting the parameter (3 rows by 2 cols)\npar(mfrow=c(3, 2))\n\n# Scatterplot\n# Note the incremental additions\n\nx &lt;- c(0.5, 2, 4, 8, 12, 16)\ny1 &lt;- c(1, 1.3, 1.9, 3.4, 3.9, 4.8)\ny2 &lt;- c(4, .8, .5, .45, .4, .3)\n\n# Setting label orientation, margins c(bottom, left, top, right) & text size\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) \nplot.new()\nplot.window(range(x), c(0, 6))\nlines(x, y1)\nlines(x, y2)\npoints(x, y1, pch=16, cex=3) \npoints(x, y2, pch=21, bg=\"lightblue\", cex=2)\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(0, 16, 4)) # What is the first number standing for? The first number in the axis() function stands for the side of the plot where the axis is drawn. 1 is the bottom, 2 is the left, 3 is top and 4 is the right side.\naxis(2, at=seq(0, 6, 2))\naxis(4, at=seq(0, 6, 2))\nbox(bty=\"u\")\nmtext(\"Travel Time (s)\", side=1, line=2, cex=0.8)\nmtext(\"Responses per Travel\", side=2, line=2, las=0, cex=0.8)\nmtext(\"Responses per Second\", side=4, line=2, las=0, cex=0.8)\ntext(4, 5, \"Bird 131\")\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n# Histogram\n# Random data\nY &lt;- rnorm(50)\n# Make sure no Y exceed [-3.5, 3.5]\nY[Y &lt; -3.5 | Y &gt; 3.5] &lt;- NA # Selection/set range\nx &lt;- seq(-3.5, 3.5, .1)\ndn &lt;- dnorm(x)\npar(mar=c(4.5, 4.1, 3.1, 0))\nhist(Y, breaks=seq(-3.5, 3.5), ylim=c(0, 0.5), \n     col=\"gray80\", freq=FALSE)\nlines(x, dnorm(x), lwd=2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Barplot\npar(mar=c(2, 3.1, 2, 2.1)) \nmidpts &lt;- barplot(VADeaths, \n                  col=gray(0.1 + seq(1, 9, 2)/11), \n                  names=rep(\"\", 4))\nmtext(sub(\" \", \"\\n\", colnames(VADeaths)),\n      at=midpts, side=1, line=0.5, cex=0.5)\ntext(rep(midpts, each=5), apply(VADeaths, 2, cumsum) - VADeaths/2,\n     VADeaths, \n     col=rep(c(\"white\", \"black\"), times=3:2), \n     cex=0.8)\npar(mar=c(5.1, 4.1, 4.1, 2.1))  \n\n# Boxplot\npar(mar=c(3, 4.1, 2, 0))\nboxplot(len ~ dose, data = ToothGrowth,\n        boxwex = 0.25, at = 1:3 - 0.2,\n        subset= supp == \"VC\", col=\"white\",\n        xlab=\"\",\n        ylab=\"tooth length\", ylim=c(0,35))\nmtext(\"Vitamin C dose (mg)\", side=1, line=2.5, cex=0.8)\nboxplot(len ~ dose, data = ToothGrowth, add = TRUE,\n        boxwex = 0.25, at = 1:3 + 0.2,\n        \n        subset= supp == \"OJ\")\nlegend(1.5, 9, c(\"Ascorbic acid\", \"Orange juice\"), \n       fill = c(\"white\", \"gray\"), \n       bty=\"n\")\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Persp\nx &lt;- seq(-10, 10, length= 30)\ny &lt;- x\nf &lt;- function(x,y) { r &lt;- sqrt(x^2+y^2); 10 * sin(r)/r }\nz &lt;- outer(x, y, f)\nz[is.na(z)] &lt;- 1\n# 0.5 to include z axis label\npar(mar=c(0, 0.5, 0, 0), lwd=0.5)\npersp(x, y, z, theta = 30, phi = 30, \n      expand = 0.5)\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n# Piechart\npar(mar=c(0, 2, 1, 2), xpd=FALSE, cex=0.5)\npie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)\nnames(pie.sales) &lt;- c(\"Blueberry\", \"Cherry\",\n                      \"Apple\", \"Boston Cream\", \"Other\", \"Vanilla\")\npie(pie.sales, col = gray(seq(0.3,1.0,length=6)))"
  },
  {
    "objectID": "assignments/assignment2.html#happy-planet-data",
    "href": "assignments/assignment2.html#happy-planet-data",
    "title": "Assignment 2",
    "section": "2 Happy Planet Data",
    "text": "2 Happy Planet Data\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(readxl)\n\nWarning: package 'readxl' was built under R version 4.3.3\n\nhpd &lt;- read_excel(\"C:/Users/kxi220002/Downloads/HPI_2024_public_dataset.xlsx\", \n    sheet = \"1. All countries\", range = \"A9:L158\")\n\nNew names:\n• `` -&gt; `...4`\n\nView(hpd)\n\n\n#Scatterplot\n\nggplot(hpd, aes_string(\"`Population (thousands)`\", \"`Carbon Footprint (tCO2e)`\")) +\n  geom_point() +\n  ggtitle(\"Population vs Carbon Footprint\") +\n  xlab(\"Population (thousands)\") +\n  ylab(\"Carbon Footprint (tCO2e)\")\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\n\n\n\n\n\n\n\n\n#Histogram\n\nggplot(hpd, aes_string(\"`GDP per capita ($)`\" )) +\n  geom_histogram(color = \"black\") +\n  ggtitle(\"Frequency of GDP Per Capita\") +\n  xlab(\"GDP per capita ($)\") +\n  ylab(\"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n#LinePlot\n\nggplot(hpd, aes_string(\"`Carbon Footprint (tCO2e)`\", \"`HPI`\" )) +\n  geom_line() +\n  ggtitle(\"Carbon Footprint vs HPI\") +\n  xlab(\"Carbon Footprint(tCO2e)\") +\n  ylab(\"Happy Planet Index(HPI\")\n\n\n\n\n\n\n\n\n\n#Box Plot\n\nggplot(hpd, aes(x = factor(Continent), y = `Life Expectancy (years)`, fill = \nfactor(Continent))) +\n  geom_boxplot() +\n  ggtitle(\"Population vs Carbon Footprint\") +\n  xlab(\"Population (thousands)\") +\n  ylab(\"Carbon Footprint (tCO2e)\")\n\n\n\n\n\n\n\n\n\n#Bar Plot\n\ntop10HPI &lt;- hpd[order(-hpd$HPI),][1:10,]\nggplot(top10HPI, aes(x = reorder(Country, HPI), y = HPI, fill = Country)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(x = \"Country\", y = \"HPI\", title = \"Top 10 Countries by HPI\")\n\n\n\n\n\n\n\n\n\n#Perspective Plot\n\nx &lt;- seq(-10, 10, length=30)\ny &lt;- x\n# Define the function for z values\nf &lt;- function(x, y) {\n r &lt;- sqrt(x^2 + y^2)\n z &lt;- sin(r) / r\n z[is.na(z)] &lt;- 1 # Handle NaN values\n return(z)\n}\n# Create the z matrix\nz &lt;- outer(x, y, f)\n# Create the 3D perspective plot\npersp(x, y, z, theta = 30, phi = 30, \n expand = 0.5, col=\"green\", border=\"black\",\n xlab=\"X\", ylab=\"Y\", zlab=\"Z\")\n\n\n\n\n\n\n\n\n\n# Pie Chart\n\ncontinent_counts &lt;- table(hpd$`Continent`)\npie(continent_counts, main=\"Pie chart of Continent distribution\")"
  },
  {
    "objectID": "assignments/assignment3.html",
    "href": "assignments/assignment3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "# Histogram\n# Random data\n\n# Generate 50 random data points from a standard normal distribution\nY &lt;- rnorm(50)\n\n# Make sure no Y exceed [-3.5, 3.5]\n# This line filters out any values in Y that are less than -3.5 or greater than 3.5 by setting them to NA\n# Useful for limiting the data range and focusing the histogram on a specific interval\nY[Y &lt; -3.5 | Y &gt; 3.5] &lt;- NA # Selection/set range\n\n# Create a sequence from -3.5 to 3.5, incremented by 0.1, for x-axis points\n# Useful for plotting the normal density later\nx &lt;- seq(-3.5, 3.5, .1)\n\n# Compute the normal density at each point in x\ndn &lt;- dnorm(x)\n\n# Set the margins of the plot (bottom, left, top, right) measured in lines of text\n# Here, the right margin is reduced to zero to adjust how the plot fits in the plotting area\npar(mar=c(4.5, 4.1, 3.1, 0))\n\n# Plot a histogram of Y\n# `breaks=seq(-3.5, 3.5)` sets the boundaries of the bins for the histogram\n# `ylim=c(0, 0.5)` sets the y-axis limits\n# `col=\"gray80\"` sets the bar color to light gray\n# `freq=FALSE` normalizes the histogram, turning it into a density plot\nhist(Y, breaks=seq(-3.5, 3.5), ylim=c(0, 0.5), \n     col=\"gray80\", freq=FALSE)\n\n# Overlay a line graph of the normal distribution density\n# `lwd=2` sets the line width to 2, making it thicker for better visibility\nlines(x, dnorm(x), lwd=2)\n\n\n\n\n\n\n\n# Reset the margins after plotting\n# Ensures that any subsequent plots have standard margins\npar(mar=c(5.1, 4.1, 4.1, 2.1))"
  },
  {
    "objectID": "assignments/assignment3.html#rerun-murrell01.r",
    "href": "assignments/assignment3.html#rerun-murrell01.r",
    "title": "Assignment 3",
    "section": "",
    "text": "# Histogram\n# Random data\n\n# Generate 50 random data points from a standard normal distribution\nY &lt;- rnorm(50)\n\n# Make sure no Y exceed [-3.5, 3.5]\n# This line filters out any values in Y that are less than -3.5 or greater than 3.5 by setting them to NA\n# Useful for limiting the data range and focusing the histogram on a specific interval\nY[Y &lt; -3.5 | Y &gt; 3.5] &lt;- NA # Selection/set range\n\n# Create a sequence from -3.5 to 3.5, incremented by 0.1, for x-axis points\n# Useful for plotting the normal density later\nx &lt;- seq(-3.5, 3.5, .1)\n\n# Compute the normal density at each point in x\ndn &lt;- dnorm(x)\n\n# Set the margins of the plot (bottom, left, top, right) measured in lines of text\n# Here, the right margin is reduced to zero to adjust how the plot fits in the plotting area\npar(mar=c(4.5, 4.1, 3.1, 0))\n\n# Plot a histogram of Y\n# `breaks=seq(-3.5, 3.5)` sets the boundaries of the bins for the histogram\n# `ylim=c(0, 0.5)` sets the y-axis limits\n# `col=\"gray80\"` sets the bar color to light gray\n# `freq=FALSE` normalizes the histogram, turning it into a density plot\nhist(Y, breaks=seq(-3.5, 3.5), ylim=c(0, 0.5), \n     col=\"gray80\", freq=FALSE)\n\n# Overlay a line graph of the normal distribution density\n# `lwd=2` sets the line width to 2, making it thicker for better visibility\nlines(x, dnorm(x), lwd=2)\n\n\n\n\n\n\n\n# Reset the margins after plotting\n# Ensures that any subsequent plots have standard margins\npar(mar=c(5.1, 4.1, 4.1, 2.1))"
  },
  {
    "objectID": "assignments/assignment3.html#rerun-anscombe01.r",
    "href": "assignments/assignment3.html#rerun-anscombe01.r",
    "title": "Assignment 3",
    "section": "2 Rerun anscombe01.R",
    "text": "2 Rerun anscombe01.R\n\nplot.new()\ndata(anscombe)\nplot(anscombe$x1,anscombe$y1)\n\n\n\n\n\n\n\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] &lt;- as.name(paste0(\"y\", i))\n  ##      ff[[3]] &lt;- as.name(paste0(\"x\", i))\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0)) \n\n# Changing color\n# changing Characters to 20 type \n# Changing CEX to 1.2\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"darkblue\", pch = 20, cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"red\", lty=\"longdash\")}\nmtext(\"Chantan's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n\n\npar(op)"
  },
  {
    "objectID": "assignments/assignment3.html#finetune-charts",
    "href": "assignments/assignment3.html#finetune-charts",
    "title": "Assignment 3",
    "section": "3 Finetune charts",
    "text": "3 Finetune charts\n\nplot.new()\npar(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0), \n    bg=\"gray90\")\n\n#Changing color\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, family=\"serif\", col = \"brown\", pch = 21, bg = \"lightblue\", \n       cex = 1.5, xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"yellow\", lty=\"longdash\")}\n\n#Changing font to serif\nmtext(\"Chantan's 4 Regression data sets\", family=\"serif\", outer = TRUE, cex = 1.5)"
  },
  {
    "objectID": "assignments/assignment3.html#ggplot2",
    "href": "assignments/assignment3.html#ggplot2",
    "title": "Assignment 3",
    "section": "4 ggplot2",
    "text": "4 ggplot2\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nggplot(anscombe, aes(x1,y1)) + \n  geom_point(shape = 21, color = \"brown\", fill = \"lightblue\", size = 4) + \n  geom_smooth(method = \"lm\", color = \"yellow\", linetype = \"longdash\", se = FALSE) + \n  theme_classic(base_family = \"serif\") + \n  labs(title=\"Chantan's Regession data set\") + \n  theme(plot.background = element_rect(fill = \"gray90\"), \n        panel.background = element_rect(fill = \"gray90\"),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 20))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "assignments/assignment3.html#pre-hackathon",
    "href": "assignments/assignment3.html#pre-hackathon",
    "title": "Assignment 3",
    "section": "5 Pre-hackathon",
    "text": "5 Pre-hackathon\n\n# Load the data\nowidall &lt;- read.csv(\"https://github.com/owid/covid-19-data/blob/master/public/data/owid-covid-data.csv?raw=true\")\nowidall &lt;- owidall[owidall$iso_code != \"OWID\", ]  # Remove 'OWID' cases\nowideu &lt;- subset(owidall, continent == \"Europe\")  # Filter European data\n\n# Filter data for the date range and ensure it's sorted by date\nowideu &lt;- subset(owideu, date &gt;= \"2020-01-01\" & date &lt;= \"2023-08-31\")\nowideu$date &lt;- as.Date(owideu$date)  # Convert date to Date class\nowideu &lt;- owideu[order(owideu$date), ]  # Order by date\n\n# Adjusting plot margins to make better use of space\npar(mar = c(4, 5, 2, 2) + 0.3)  # Adjust margins: bottom, left, top, right\n\n# Plot setup with specified axis limits and no default axes\nplot(owideu$date, owideu$new_deaths, type = 'p', col = rgb(214/255, 20/255, 133/255), \n     xlab = \"\", ylab = \"\", xlim = range(owideu$date), ylim = c(0, 6000), xaxt = 'n', yaxt = 'n',\n     pch = 19, cex = 0.4)  # Reduced point size for clarity\n\n# Adding a loess smoothed trend line\nlines(lowess(owideu$date, owideu$new_deaths), col = rgb(255/255, 105/255, 180/255))  # Adjusted for a pinker color\n\n# Customize the x-axis to show specific dates only and not auto-generate year markers\naxis_dates &lt;- c(\"2020-01-01\", \"2020-02-01\", \"2020-04-01\", \"2020-06-01\", \"2020-08-01\", \n                \"2020-10-01\", \"2020-11-01\", \"2021-01-01\", \"2021-03-01\", \"2021-05-01\",\n                \"2021-07-01\", \"2021-08-01\", \"2021-10-01\", \"2021-12-01\", \"2022-02-01\", \n                \"2022-04-01\", \"2022-06-01\", \"2022-07-01\", \"2022-09-01\", \"2022-11-01\", \n                \"2023-01-01\", \"2023-03-01\", \"2023-04-01\", \"2023-06-01\", \"2023-08-01\")\naxis(1, at = as.Date(axis_dates), labels = format(as.Date(axis_dates), \"%Y-%m\"), las = 2, cex.axis = 0.5, tck = -0.0001)\n\n# Customize the y-axis with specified breaks and vertical labels\naxis(2, at = c(0, 1000, 3000, 5000), labels = c(\"0\", \"1000\", \"3000\", \"5000\"), las = 0, cex.axis = 0.5)\n\n# Add x-axis and y-axis labels with adjusted font size and position\nmtext(\"Date\", side = 1, line = 3, cex = 0.7)\nmtext(\"COVID Deaths in Europe (Daily)\", side = 2, line = 2, cex = 0.7)\n\n# Add a box around the plot\nbox()"
  },
  {
    "objectID": "assignments/assignment4.html",
    "href": "assignments/assignment4.html",
    "title": "Assignment 4",
    "section": "",
    "text": "library(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\nyear_2021_data &lt;- subset(roaddeaths, Year == 2021)\n\n# Filter total deaths for all ages and both sexes\ntotal_deaths_2021 &lt;- year_2021_data %&gt;%\n  filter(Sex == \"All\" & Age.Group == \"[All]\")\n\n# Specify the number of top countries \nT &lt;- 5\n# Get the top 5 countries with the highest road accidents in 2019\ntop_5_countries &lt;- total_deaths_2021 %&gt;%\n  top_n(T, Number)\n\ntop_5_countries\n\n  Region.Code                    Region Country.Code    Country Year Sex\n1          OA                   Oceania          AUS  Australia 2021 All\n2         CSA Central and South America          ECU    Ecuador 2021 All\n3          EU                    Europe          ESP      Spain 2021 All\n4          AS                      Asia          KAZ Kazakhstan 2021 All\n5          EU                    Europe          SRB     Serbia 2021 All\n  Age.group.code Age.Group Number\n1        Age_all     [All]   1131\n2        Age_all     [All]   3190\n3        Age_all     [All]   1645\n4        Age_all     [All]   1599\n5        Age_all     [All]    474\n  Percentage.of.cause.specific.deaths.out.of.total.deaths\n1                                               0.6595945\n2                                               3.0309365\n3                                               0.3649522\n4                                               0.8766303\n5                                               0.3469427\n  Age.standardized.death.rate.per.100.000.standard.population\n1                                                    4.062440\n2                                                   17.879492\n3                                                    3.038423\n4                                                    8.617921\n5                                                    5.617079\n  Death.rate.per.100.000.population\n1                          4.402820\n2                         17.832711\n3                          3.475501\n4                          8.414541\n5                          6.935578\n\n#Some calculations for ploting\ntop_5_countries$wc &lt;- cumsum(top_5_countries$Death.rate.per.100.000.population)\ntop_5_countries$sp &lt;-top_5_countries$wc - top_5_countries$Death.rate.per.100.000.population\ntop_5_countries$mp &lt;- with(top_5_countries,sp +(wc-sp)/2)\n\ntop_5_countries$wc\n\n[1]  4.40282 22.23553 25.71103 34.12557 41.06115\n\ntop_5_countries$mp\n\n[1]  2.20141 13.31918 23.97328 29.91830 37.59336\n\n# plotting\n\ncustom_colors &lt;- c(\"Australia\" = \"darkred\", \"Ecuador\" = \"orange\", \n                   \"Spain\" = \"seagreen\", \"Kazakhstan\" = \"skyblue\", \n                   \"Serbia\" = \"orchid\")\nggplot(top_5_countries, aes(ymin= 0)) +\n  geom_rect((aes(xmin = sp, xmax = wc, ymax = Number, fill = Country))) +\n  geom_text(aes(x = mp, y = Number * 0.5, label = c(\"Australia\", \"Ecuador\", \n                                                    \"Spain\", \"Kazakhstan\", \"Serbia\"))) + \n  theme_bw() + \n  theme(legend.position = \"none\") + \n  labs(\n    title = \"Road Accidents Deaths and Death Rates for Countries with Highest Mortality\",\n    x = \"Death Rate (per 100,000 population)\",\n    y = \"Number of Road Accident Deaths\",\n  ) +\n  scale_fill_manual(values = custom_colors)"
  },
  {
    "objectID": "assignments/assignment4.html#variable-with-column-chart",
    "href": "assignments/assignment4.html#variable-with-column-chart",
    "title": "Assignment 4",
    "section": "2 Variable with Column Chart",
    "text": "2 Variable with Column Chart\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\nyear_2021_data &lt;- subset(roaddeaths, Year == 2021)\n\n# Filter total deaths for all ages and both sexes\ntotal_deaths_2021 &lt;- year_2021_data %&gt;%\n  filter(Sex == \"All\" & Age.Group == \"[All]\")\n\n# Specify the number of top countries \nT &lt;- 5\n# Get the top 5 countries with the highest road accidents in 2019\ntop_5_countries &lt;- total_deaths_2021 %&gt;%\n  top_n(T, Number)\n\ntop_5_countries\n\n  Region.Code                    Region Country.Code    Country Year Sex\n1          OA                   Oceania          AUS  Australia 2021 All\n2         CSA Central and South America          ECU    Ecuador 2021 All\n3          EU                    Europe          ESP      Spain 2021 All\n4          AS                      Asia          KAZ Kazakhstan 2021 All\n5          EU                    Europe          SRB     Serbia 2021 All\n  Age.group.code Age.Group Number\n1        Age_all     [All]   1131\n2        Age_all     [All]   3190\n3        Age_all     [All]   1645\n4        Age_all     [All]   1599\n5        Age_all     [All]    474\n  Percentage.of.cause.specific.deaths.out.of.total.deaths\n1                                               0.6595945\n2                                               3.0309365\n3                                               0.3649522\n4                                               0.8766303\n5                                               0.3469427\n  Age.standardized.death.rate.per.100.000.standard.population\n1                                                    4.062440\n2                                                   17.879492\n3                                                    3.038423\n4                                                    8.617921\n5                                                    5.617079\n  Death.rate.per.100.000.population\n1                          4.402820\n2                         17.832711\n3                          3.475501\n4                          8.414541\n5                          6.935578\n\n#Some calculations for ploting\ntop_5_countries$wc &lt;- cumsum(top_5_countries$Death.rate.per.100.000.population)\ntop_5_countries$sp &lt;-top_5_countries$wc - top_5_countries$Death.rate.per.100.000.population\ntop_5_countries$mp &lt;- with(top_5_countries,sp +(wc-sp)/2)\n\ntop_5_countries$wc\n\n[1]  4.40282 22.23553 25.71103 34.12557 41.06115\n\ntop_5_countries$mp\n\n[1]  2.20141 13.31918 23.97328 29.91830 37.59336\n\n# plotting\n\ncustom_colors &lt;- c(\"Australia\" = \"darkred\", \"Ecuador\" = \"orange\", \n                   \"Spain\" = \"seagreen\", \"Kazakhstan\" = \"skyblue\", \n                   \"Serbia\" = \"orchid\")\nggplot(top_5_countries, aes(ymin= 0)) +\n  geom_rect((aes(xmin = sp, xmax = wc, ymax = Number, fill = Country))) +\n  geom_text(aes(x = mp, y = Number * 0.5, label = c(\"Australia\", \"Ecuador\", \n                                                    \"Spain\", \"Kazakhstan\", \"Serbia\"))) + \n  theme_bw() + \n  theme(legend.position = \"none\") + \n  labs(\n    title = \"Road Accidents Deaths and Death Rates for Countries with Highest Mortality\",\n    x = \"Death Rate (per 100,000 population)\",\n    y = \"Number of Road Accident Deaths\",\n  ) +\n  scale_fill_manual(values = custom_colors)"
  },
  {
    "objectID": "assignments/assignment4.html#table-or-table-with-embedded-charts",
    "href": "assignments/assignment4.html#table-or-table-with-embedded-charts",
    "title": "Assignment 4",
    "section": "3 Table or Table with Embedded Charts",
    "text": "3 Table or Table with Embedded Charts\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(reshape2)\n\nWarning: package 'reshape2' was built under R version 4.3.3\n\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\nyear_2019_2020_data &lt;- subset(roaddeaths, Year == 2019 | Year == 2020)\n\nroad_deaths_2019_2020 &lt;- year_2019_2020_data %&gt;%\n  filter(Sex == \"All\" & Age.Group == \"[All]\")\n\n# Specify the number of top countries\nT &lt;- 4\n\n# Get the top 4 countries with the highest road accident deaths\ntop_countries&lt;- road_deaths_2019_2020 %&gt;%\n  top_n(T,Number )\n\ncustom_colors &lt;- c(\"2019\" = \"brown\", \"2020\" = \"darkgreen\")\n\nggplot(top_countries, aes(x = Country, y = Number, fill = as.factor(Year))) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  facet_grid(~ Country, scales = \"free_y\") +\n  theme(axis.text.x = element_blank()) +\n  labs(title = \"Road Accident Deaths\", x = NULL, y = \"Number of Deaths\") +\n  scale_fill_manual(values = custom_colors)"
  },
  {
    "objectID": "assignments/assignment4.html#bar-chart",
    "href": "assignments/assignment4.html#bar-chart",
    "title": "Assignment 4",
    "section": "4 Bar Chart",
    "text": "4 Bar Chart\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\nyear_2019_data &lt;- subset(roaddeaths, Year == 2019)\n\n# Filter the dataset for USA\nusa_2019 &lt;- subset(year_2019_data, Country == \"United States of America\" \n                   & Age.Group != \"[All]\" & Age.Group != \"[Unknown]\")\n\n# Reorder the levels of Age.Group\nusa_2019$Age.Group &lt;- factor(usa_2019$Age.Group, \n                             levels = c(\"[0]\", \"[1-4]\", \"[5-9]\", \"[10-14]\", \n                                        \"[15-19]\", \"[20-24]\", \"[25-29]\", \"[30-34]\",                                         \"[35-39]\", \"[40-44]\", \"[45-49]\", \"[50-54]\",                                         \"[55-59]\", \"[60-64]\", \"[65-69]\", \"[70-74]\",                                         \"[75-79]\", \"[80-84]\", \"[85+]\"))\n\n# Create the bar plot\nggplot(usa_2019, aes(x = Number)) +\n  geom_bar(aes(y = Age.Group), position = \"dodge\", stat = \"identity\", fill = \"darkred\") +\n  labs(\n    title = \"Road Accident Deaths in the USA by Age Group (2019)\",\n    x = \"Number of Road Traffic Accidents\",\n    y = \"Age Group\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "assignments/assignment4.html#column-chart",
    "href": "assignments/assignment4.html#column-chart",
    "title": "Assignment 4",
    "section": "5 Column Chart",
    "text": "5 Column Chart\n\nlibrary(ggplot2)\n\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\nyear_2019_data &lt;- subset(roaddeaths, Year == 2019)\n\n# Create a clustered bar chart\n\nggplot(year_2019_data, aes(x = Region)) +\n  geom_col(aes(y = Number, fill = Sex), position = \"dodge\", stat = \"identity\") +\n  scale_fill_manual(values = c(\"Male\" = \"navy\", \"Female\" = \"chocolate\", \"All\" = \"grey\")) +\n  labs(\n    title = \"Road Accident Deaths by Gender and Region (2019)\",\n    x = NULL,\n    y = \"Number of Road Traffic Accidents\",\n    fill = \"Gender\"\n  ) +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nWarning in geom_col(aes(y = Number, fill = Sex), position = \"dodge\", stat =\n\"identity\"): Ignoring unknown parameters: `stat`\n\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_col()`)."
  },
  {
    "objectID": "assignments/assignment5.html",
    "href": "assignments/assignment5.html",
    "title": "Assignment 5",
    "section": "",
    "text": "# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the year 2019\nyear_2019_data &lt;- subset(roaddeaths, Year == 201)\n\n# Filter the dataset for Pakistan\nusa&lt;- subset(roaddeaths, Country == \"United States of America\" \n                   & Age.Group == \"[All]\" & Sex == \"All\")\n\nusa_numbers&lt;- usa$Number\n\n# Create a histogram\nhist(usa_numbers, \n     main = \"Distribution of USA Road Accident Deaths\",\n     xlab = \"Number of Road Deaths\",\n     ylab = \"Frequency\",\n     col = \"darkred\",  # Bar color\n     border = \"black\",   # Border color\n     xlim = c(min(usa_numbers), max(usa_numbers)),\n     axes = TRUE,\n     labels = FALSE,\n     probability = FALSE)  # Set to FALSE to get frequency and not probability density\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n\n# Filter the dataset for the year 2019\nusa_2019 &lt;- subset(roaddeaths, Country == \"United States of America\" \n                   & Age.Group != \"[All]\" & Age.Group != \"[Unknown]\"\n                   & Year == 2019 & Sex == \"All\")\n\n# Reorder the levels of Age.Group\nusa_2019$Age.Group &lt;- factor(usa_2019$Age.Group, \n                             levels = c(\"[0]\", \"[1-4]\", \"[5-9]\", \"[10-14]\", \"[15-19]\",\n                                        \"[20-24]\", \"[25-29]\", \"[30-34]\", \"[35-39]\",\n                                        \"[40-44]\", \"[45-49]\", \"[50-54]\", \"[55-59]\", \n                                        \"[60-64]\", \"[65-69]\", \"[70-74]\", \"[75-79]\", \n                                        \"[80-84]\", \"[85+]\"))\n\n# Create a matrix of values for the barplot (using \"Number\" as width)\nbarplot_matrix &lt;- t(table(usa_2019$Age.Group) * usa_2019$Number)\n\n# Create the horizontal bar plot\nbarplot(barplot_matrix, beside = TRUE, col = \"darkgrey\", horiz = TRUE,\n        main = \"Road Accident Deaths in the USA by Age Group (2019)\",\n        ylab = \"Age Group\", xlab = \"Number of Road Traffic Accidents\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the year 2019\nyear_2019_data &lt;- subset(roaddeaths, Year == 2019)\n# Define the list of countries you want to select\nselected_countries &lt;- c(\"United States of America\", \"Germany\", \"Japan\",\n                        \"United Kingdom of Great Britain and Northern Ireland\", \"Italy\", \"Canada\", \"France\")\n\n# Filter the dataset for the selected countries\nselected_data &lt;- subset(roaddeaths, Country %in% selected_countries \n                        & Age.Group == \"[All]\" & Sex != \"All\" & Year == 2019)\n\n# Define custom colors for the gender\ncustom_colors &lt;- c(\"Male\" = \"skyblue\", \"Female\" = \"lightpink\")\n\n# Create the bar plot\nbarplot(height = selected_data$Number, beside = TRUE, col = custom_colors,\n        names.arg = selected_data$Country.Code,\n        main = \"Road Accident Deaths for G7 Countries (2019)\",\n        xlab = \"Country\", ylab = \"Number of Road Traffic Accidents\")\n\n# Add a legend\nlegend(\"center\", legend = names(custom_colors), fill = custom_colors)\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the USA, year 2019, all ages, and specific gender\nusa_2019_gender &lt;- subset(roaddeaths, Country == \"United States of America\" \n                          & Year == 2019 & Age.Group == \"[All]\" & Sex != \"All\")\n\n# Sum deaths by gender\ngender_deaths &lt;- tapply(usa_2019_gender$Number, usa_2019_gender$Sex, sum)\n\n# Create a pie chart\npie(gender_deaths,\n    main = \"Proportion of Road Accident Deaths by Gender in USA (2019)\",\n    col = c(\"skyblue\", \"lightpink\"),\n    labels = paste(names(gender_deaths), \"\\n\", gender_deaths))\n\n# Add a legend\nlegend(\"bottomright\", legend = names(gender_deaths), fill = c(\"skyblue\", \"lightpink\"))\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter for selected countries and 2019\nselected_data &lt;- subset(roaddeaths, Country %in% c(\"United States of America\", \"Germany\", \"Japan\",\n                                                   \"United Kingdom\", \"Italy\", \"Canada\", \"France\")\n                        & Year == 2019 & Age.Group == \"[All]\" & Sex == \"All\")\n\n# Create a boxplot\nboxplot(Number ~ Country, data = selected_data,\n        main = \"Boxplot of Road Accident Deaths by Country (2019)\",\n        ylab = \"Number of Road Traffic Accidents\",\n        col = rainbow(n = length(unique(selected_data$Country))),\n        las = 1)  # Orient axis labels vertically\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the USA, 2019, and not unknown age groups\nusa_2019_ages &lt;- subset(roaddeaths, Country == \"United States of America\" \n                        & Year == 2019 & Age.Group != \"[Unknown]\" & Age.Group != \"[All]\" & Sex == \"All\")\n\n# Convert age groups to a numeric scale for plotting\nusa_2019_ages$Age.Numeric &lt;- as.numeric(as.factor(usa_2019_ages$Age.Group))\n\n# Create a scatterplot\nplot(usa_2019_ages$Age.Numeric, usa_2019_ages$Number,\n     main = \"Scatterplot of Road Accident Deaths by Age Group in USA (2019)\",\n     xlab = \"Age Group (Encoded)\",\n     ylab = \"Number of Road Traffic Accidents\",\n     pch = 19,\n     col = \"green\")"
  },
  {
    "objectID": "assignments/assignment5.html#base-r-graphics",
    "href": "assignments/assignment5.html#base-r-graphics",
    "title": "Assignment 5",
    "section": "",
    "text": "# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the year 2019\nyear_2019_data &lt;- subset(roaddeaths, Year == 201)\n\n# Filter the dataset for Pakistan\nusa&lt;- subset(roaddeaths, Country == \"United States of America\" \n                   & Age.Group == \"[All]\" & Sex == \"All\")\n\nusa_numbers&lt;- usa$Number\n\n# Create a histogram\nhist(usa_numbers, \n     main = \"Distribution of USA Road Accident Deaths\",\n     xlab = \"Number of Road Deaths\",\n     ylab = \"Frequency\",\n     col = \"darkred\",  # Bar color\n     border = \"black\",   # Border color\n     xlim = c(min(usa_numbers), max(usa_numbers)),\n     axes = TRUE,\n     labels = FALSE,\n     probability = FALSE)  # Set to FALSE to get frequency and not probability density\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n\n# Filter the dataset for the year 2019\nusa_2019 &lt;- subset(roaddeaths, Country == \"United States of America\" \n                   & Age.Group != \"[All]\" & Age.Group != \"[Unknown]\"\n                   & Year == 2019 & Sex == \"All\")\n\n# Reorder the levels of Age.Group\nusa_2019$Age.Group &lt;- factor(usa_2019$Age.Group, \n                             levels = c(\"[0]\", \"[1-4]\", \"[5-9]\", \"[10-14]\", \"[15-19]\",\n                                        \"[20-24]\", \"[25-29]\", \"[30-34]\", \"[35-39]\",\n                                        \"[40-44]\", \"[45-49]\", \"[50-54]\", \"[55-59]\", \n                                        \"[60-64]\", \"[65-69]\", \"[70-74]\", \"[75-79]\", \n                                        \"[80-84]\", \"[85+]\"))\n\n# Create a matrix of values for the barplot (using \"Number\" as width)\nbarplot_matrix &lt;- t(table(usa_2019$Age.Group) * usa_2019$Number)\n\n# Create the horizontal bar plot\nbarplot(barplot_matrix, beside = TRUE, col = \"darkgrey\", horiz = TRUE,\n        main = \"Road Accident Deaths in the USA by Age Group (2019)\",\n        ylab = \"Age Group\", xlab = \"Number of Road Traffic Accidents\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the year 2019\nyear_2019_data &lt;- subset(roaddeaths, Year == 2019)\n# Define the list of countries you want to select\nselected_countries &lt;- c(\"United States of America\", \"Germany\", \"Japan\",\n                        \"United Kingdom of Great Britain and Northern Ireland\", \"Italy\", \"Canada\", \"France\")\n\n# Filter the dataset for the selected countries\nselected_data &lt;- subset(roaddeaths, Country %in% selected_countries \n                        & Age.Group == \"[All]\" & Sex != \"All\" & Year == 2019)\n\n# Define custom colors for the gender\ncustom_colors &lt;- c(\"Male\" = \"skyblue\", \"Female\" = \"lightpink\")\n\n# Create the bar plot\nbarplot(height = selected_data$Number, beside = TRUE, col = custom_colors,\n        names.arg = selected_data$Country.Code,\n        main = \"Road Accident Deaths for G7 Countries (2019)\",\n        xlab = \"Country\", ylab = \"Number of Road Traffic Accidents\")\n\n# Add a legend\nlegend(\"center\", legend = names(custom_colors), fill = custom_colors)\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the USA, year 2019, all ages, and specific gender\nusa_2019_gender &lt;- subset(roaddeaths, Country == \"United States of America\" \n                          & Year == 2019 & Age.Group == \"[All]\" & Sex != \"All\")\n\n# Sum deaths by gender\ngender_deaths &lt;- tapply(usa_2019_gender$Number, usa_2019_gender$Sex, sum)\n\n# Create a pie chart\npie(gender_deaths,\n    main = \"Proportion of Road Accident Deaths by Gender in USA (2019)\",\n    col = c(\"skyblue\", \"lightpink\"),\n    labels = paste(names(gender_deaths), \"\\n\", gender_deaths))\n\n# Add a legend\nlegend(\"bottomright\", legend = names(gender_deaths), fill = c(\"skyblue\", \"lightpink\"))\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter for selected countries and 2019\nselected_data &lt;- subset(roaddeaths, Country %in% c(\"United States of America\", \"Germany\", \"Japan\",\n                                                   \"United Kingdom\", \"Italy\", \"Canada\", \"France\")\n                        & Year == 2019 & Age.Group == \"[All]\" & Sex == \"All\")\n\n# Create a boxplot\nboxplot(Number ~ Country, data = selected_data,\n        main = \"Boxplot of Road Accident Deaths by Country (2019)\",\n        ylab = \"Number of Road Traffic Accidents\",\n        col = rainbow(n = length(unique(selected_data$Country))),\n        las = 1)  # Orient axis labels vertically\n\n\n\n\n\n\n\n\n\n\n\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the USA, 2019, and not unknown age groups\nusa_2019_ages &lt;- subset(roaddeaths, Country == \"United States of America\" \n                        & Year == 2019 & Age.Group != \"[Unknown]\" & Age.Group != \"[All]\" & Sex == \"All\")\n\n# Convert age groups to a numeric scale for plotting\nusa_2019_ages$Age.Numeric &lt;- as.numeric(as.factor(usa_2019_ages$Age.Group))\n\n# Create a scatterplot\nplot(usa_2019_ages$Age.Numeric, usa_2019_ages$Number,\n     main = \"Scatterplot of Road Accident Deaths by Age Group in USA (2019)\",\n     xlab = \"Age Group (Encoded)\",\n     ylab = \"Number of Road Traffic Accidents\",\n     pch = 19,\n     col = \"green\")"
  },
  {
    "objectID": "assignments/assignment5.html#ggplot2",
    "href": "assignments/assignment5.html#ggplot2",
    "title": "Assignment 5",
    "section": "2 ggplot2",
    "text": "2 ggplot2\n\n2.1 Histogram\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the USA, 2019, and not the \"All\" age group\nusa_ages_2019 &lt;- subset(roaddeaths, Country == \"United States of America\" &\n                                     Year == 2019 &\n                                     Age.Group != \"[All]\" & \n                                     Age.Group != \"[Unknown]\" &\n                                     Sex == \"All\")\n\n# Plot a histogram for age-wise distribution of road accident deaths\nggplot(usa_ages_2019, aes(x = Age.Group, y = Number)) + \n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  ggtitle(\"Age-Wise Distribution of Road Accident Deaths in USA (2019)\") +\n  xlab(\"Age Group\") +\n  ylab(\"Number of Road Traffic Accidents\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n2.2 Horizontal Bar Chart\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the year 2019\nyear_2019_data &lt;- subset(roaddeaths, Year == 2019)\n# Filter the dataset for USA\nusa_2019 &lt;- subset(year_2019_data, Country == \"United States of America\" \n                   & Age.Group != \"[All]\" & Age.Group != \"[Unknown]\")\n\n# Reorder the levels of Age.Group\nusa_2019$Age.Group &lt;- factor(usa_2019$Age.Group, \n                             levels = c(\"[0]\", \"[1-4]\", \"[5-9]\", \"[10-14]\", \"[15-19]\",\n                                        \"[20-24]\", \"[25-29]\", \"[30-34]\", \"[35-39]\",\n                                        \"[40-44]\", \"[45-49]\", \"[50-54]\", \"[55-59]\", \n                                        \"[60-64]\", \"[65-69]\", \"[70-74]\", \"[75-79]\", \n                                        \"[80-84]\", \"[85+]\"))\n\n# Create the bar plot\n\nggplot(usa_2019, aes(x = Number)) +\n  geom_bar(aes(y = Age.Group), position = \"dodge\", stat = \"identity\", fill = \"orange\") +\n  labs(\n    title = \"Road Accident Deaths in the USA by Age Group (2019)\",\n    x = \"Number of Road Traffic Accidents\",\n    y = \"Age Group\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.3 Vertical Bar Chart\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Load the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\n\n# Filter the dataset for the year 2019\nyear_2019_data &lt;- subset(roaddeaths, Year == 2019)\n\n# Define the list of countries\nselected_countries &lt;- c(\"United States of America\", \"Germany\", \"Japan\",\n\"United Kingdom of Great Britain and Northern Ireland\", \"Italy\", \"Canada\", \"France\")\n\n# Filter the dataset for the selected countries\nselected_data &lt;- subset(roaddeaths, Country %in% selected_countries \n                        & Age.Group == \"[All]\" & Sex != \"All\" & Year == 2019)\n# Define custom colors for the gender\ncustom_colors &lt;- c(\"Male\" = \"skyblue\", \"Female\" = \"pink\")\n\n# Create the bar plot\nggplot(selected_data, aes(x = Country.Code, y = Number, fill = Sex)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  labs(\n    title = \"Road Accident Deaths by Gender for G7 Countries (2019)\",\n    x = \"Country\",\n    y = \"Number of Road Traffic Accidents\"\n  ) +\n  scale_fill_manual(values = custom_colors) +  # Specify custom colors\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.4 Pie Chart\n\nlibrary(ggplot2)\n\n# Load and prepare the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\nusa &lt;- subset(roaddeaths, Country == \"United States of America\" & Year == 2019 & Age.Group == \"[All]\" & Sex == \"All\")\n\n# Sum deaths by gender for the USA in 2019\nusa_2019_gender &lt;- subset(roaddeaths, Country == \"United States of America\" & Year == 2019 & Age.Group == \"[All]\" & Sex != \"All\")\ngender_deaths &lt;- usa_2019_gender %&gt;%\n  group_by(Sex) %&gt;%\n  summarise(Number = sum(Number))\n\n# Using coord_polar to create a pie chart\nggplot(gender_deaths, aes(x = \"\", y = Number, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") +\n  theme_void() +\n  ggtitle(\"Proportion of Road Accident Deaths by Gender in USA (2019)\")\n\n\n\n\n\n\n\n\n\n\n2.5 Boxplot\n\nlibrary(ggplot2)\n\n# Load and prepare the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\nusa &lt;- subset(roaddeaths, Country == \"United States of America\" & Year == 2019 & Age.Group == \"[All]\" & Sex == \"All\")\n\n# Filter data for selected countries in 2019\nselected_countries &lt;- c(\"United States of America\", \"Germany\", \"Japan\", \"United Kingdom\", \"Italy\", \"Canada\", \"France\")\nselected_data &lt;- subset(roaddeaths, Country %in% selected_countries & Year == 2019 & Age.Group == \"[All]\" & Sex == \"All\")\n\nggplot(selected_data, aes(x = Country, y = Number, fill = Country)) +\n  geom_boxplot(outlier.colour = \"red\", outlier.shape = 1, width = 0.6) +  # Show outliers in red, adjust width\n  ggtitle(\"Boxplot of Road Accident Deaths by Country (2019)\") +\n  ylab(\"Number of Road Traffic Accidents\") +\n  xlab(\"Country\") +\n  ylim(0, 500) +  # Adjust this limit based on your specific data range\n  scale_y_continuous(trans = 'log10') +  # Apply a logarithmic transformation\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\n\n\n2.6 Scatterplot\n\nlibrary(ggplot2)\n\n# Load and prepare the data\nroaddeaths &lt;- read.csv(\"C:/Users/kxi220002/Downloads/Road traffic accidents.csv\")\nusa &lt;- subset(roaddeaths, Country == \"United States of America\" & Year == 2019 & Age.Group == \"[All]\" & Sex == \"All\")\n\nggplot(usa_2019_ages, aes(x = Age.Group, y = Number)) +\n  geom_point(aes(color = Age.Group), size = 3) +\n  ggtitle(\"Scatterplot of Road Accident Deaths by Age Group in USA (2019)\") +\n  xlab(\"Age Group\") +\n  ylab(\"Number of Road Traffic Accidents\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "assignments/assignment6.html#reactivity",
    "href": "assignments/assignment6.html#reactivity",
    "title": "Assignment 6",
    "section": "2 Reactivity",
    "text": "2 Reactivity"
  },
  {
    "objectID": "assignments/exercises.html",
    "href": "assignments/exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "In his 2016 presentation, Edward Tufte discusses the evolution of data visualization, emphasizing the need for clarity, precision, and efficiency in presentations. He advocates for integrating statistical thinking with visual design to enhance understanding and decision-making. Tufte highlights the importance of data density in visualizations, using Google Maps as an example of effective complex data communication.\nTufte also addresses the replication crisis in research, citing significant studies to emphasize the need for honest and rigorous data analysis. He warns against manipulating data to fit narratives, suggesting that confirmatory data analysis should adhere to pre-specified methods like those used by the CDC.\nMoreover, Tufte encourages a hands-on approach to understanding data generation and its real-world implications. This method promotes a comprehensive understanding of data and its context, which is crucial for producing relevant and reliable visual representations.\nOverall, Tufte’s lecture serves as both a critical examination of current practices in data analysis and a guide to future innovations. His call for integrity in data visualization and analysis resonates strongly with anyone aspiring to enter the field, offering essential insights for conducting ethical and effective research."
  },
  {
    "objectID": "assignments/exercises.html#hackathon-1",
    "href": "assignments/exercises.html#hackathon-1",
    "title": "Exercises",
    "section": "5 Hackathon 1",
    "text": "5 Hackathon 1\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(gridExtra)\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.3.3\n\nlibrary(RColorBrewer)\n\n# Color palette\npalette_cut &lt;- brewer.pal(n = 5, name = \"Dark2\")\n\n# Base size for themes\nbase_size &lt;- 8  # Further reduced for better proportionality\n\n# Histogram\nhist_plot &lt;- ggplot(diamonds, aes(x = price)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"gray80\", color = \"lightblue\") +\n  stat_function(fun = dnorm, args = list(mean = mean(diamonds$price), sd = sd(diamonds$price)), color = \"red\", size = 0.75) +\n  labs(title = \"Histogram of Diamond Prices\", x = \"Price\", y = \"Density\") +\n  theme_minimal(base_size = base_size) +\n  theme(plot.title = element_text(size = 12), axis.title = element_text(size = 10))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n# Bar Plot\nbar_plot &lt;- diamonds %&gt;%\n  group_by(cut) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  ggplot(aes(x = cut, y = count, fill = cut)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Bar Plot: Count of Diamonds by Cut\", x = \"Cut\", y = \"Count\") +\n  scale_fill_manual(values = palette_cut) +\n  theme_minimal(base_size = base_size) +\n  theme(plot.title = element_text(size = 12), legend.text = element_text(size = 8), legend.title = element_text(size = 10))\n\n# Box Plot\nbox_plot &lt;- ggplot(diamonds, aes(x = cut, y = price, fill = cut)) +\n  geom_boxplot() +\n  labs(title = \"Box Plot: Price Distribution by Cut\", x = \"Cut\", y = \"Price\") +\n  scale_fill_manual(values = palette_cut) +\n  theme_minimal(base_size = base_size) +\n  theme(plot.title = element_text(size = 12), axis.title = element_text(size = 10))\n\n# Scatter Plot\nfacet_scatter &lt;- ggplot(diamonds, aes(x = carat, y = price, color = color)) +\n  geom_point(alpha = 0.5, size = 1) +\n  facet_wrap(~ cut) +\n  labs(title = \"Faceted Scatter Plot: Carat vs Price by Color\", x = \"Carat\", y = \"Price\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_minimal(base_size = base_size) +\n  theme(plot.title = element_text(size = 12))\n\n# Heatmap\nheatmap_data &lt;- diamonds %&gt;%\n  group_by(cut, color) %&gt;%\n  summarise(avg_price = mean(price), .groups = \"drop\")\nheatmap &lt;- ggplot(heatmap_data, aes(x = cut, y = color, fill = avg_price)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"lightgreen\", high = \"darkgreen\") +\n  labs(title = \"Heatmap: Average Price by Cut and Color\", x = \"Cut\", y = \"Color\") +\n  theme_minimal(base_size = base_size) +\n  theme(plot.title = element_text(size = 12))\n\n# Pie Chart\npie_data &lt;- diamonds %&gt;%\n  group_by(cut) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  mutate(percentage = count / sum(count))\npie_chart &lt;- ggplot(pie_data, aes(x = \"\", y = percentage, fill = cut)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") +\n  labs(title = \"Pie Chart of Diamond Cuts\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  theme_void(base_size = base_size) +\n  theme(plot.title = element_text(size = 12))\n\n# Arrange all plots\ngrid.arrange(\n  hist_plot, bar_plot,\n  box_plot, facet_scatter,\n  heatmap, pie_chart,\n  ncol = 2\n)"
  },
  {
    "objectID": "assignments/assignment7.html",
    "href": "assignments/assignment7.html",
    "title": "Assignment 7",
    "section": "",
    "text": "https://karimdibpl.shinyapps.io/hackathon2/"
  },
  {
    "objectID": "assignments/assignment7.html#hackathon-2.0",
    "href": "assignments/assignment7.html#hackathon-2.0",
    "title": "Assignment 7",
    "section": "",
    "text": "https://karimdibpl.shinyapps.io/hackathon2/"
  },
  {
    "objectID": "assignments/assignment6.html#horsepower",
    "href": "assignments/assignment6.html#horsepower",
    "title": "Assignment 6",
    "section": "3 Horsepower",
    "text": "3 Horsepower\n\nlibrary(shiny)\n\nWarning: package 'shiny' was built under R version 4.3.3\n\nlibrary(datasets)\n\n# Load the mtcars dataset\ndata(\"mtcars\")\nmpgData &lt;- mtcars\nmpgData$am &lt;- factor(mpgData$am, labels = c(\"Automatic\", \"Manual\"))  # Enhance factor labels for 'am'\n\n# Define UI for the application\nui &lt;- fluidPage(\n  titlePanel(\"Horsepower Analysis\"),\n  sidebarLayout(\n    sidebarPanel(\n      selectInput(\"variable\", \"Variable:\",\n                  choices = c(\"Cylinders\" = \"cyl\", \"Transmission\" = \"am\", \"Gears\" = \"gear\")),\n      checkboxInput(\"outliers\", \"Show outliers\", TRUE)\n    ),\n    mainPanel(\n      h3(textOutput(\"caption\")),\n      plotOutput(\"hpPlot\")\n    )\n  )\n)\n\n# Define server logic for the application\nserver &lt;- function(input, output) {\n  # Compute the formula text dynamically based on user input\n  formulaText &lt;- reactive({\n    paste(\"hp ~\", input$variable)  # Construct the formula for plotting\n  })\n\n  # Display the current formula as a caption\n  output$caption &lt;- renderText({\n    formulaText()\n  })\n\n  # Generate a plot based on the selected variable and outlier preference\n  output$hpPlot &lt;- renderPlot({\n    boxplot(as.formula(formulaText()), data = mpgData, outline = input$outliers,\n            col = \"#75AADB\", pch = 19)  # Custom styling\n  })\n}\n\n# Run the application\nshinyApp(ui, server)\n\nPhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.\n\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "assignments/assignment8.html",
    "href": "assignments/assignment8.html",
    "title": "Final Project Storyboard: Team John Doe",
    "section": "",
    "text": "(Narrative in main window)\n\nThis project is about visualization of the public spending on saving environment.\n\n(Text in side window)\nPrerequisite: install.packages(c(“flexdashboard”,“rbokeh”,“leaflet”, “mapview”, “tidycensus”))\nThis storyboard delivers the final project product by exhibiting the final project in pages.\n\n\n\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'gapminder' was built under R version 4.3.3\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\n\n\n\n\n\n\n\n\nNarrative of Gapminder data.\n\n\n\n\nlibrary(ggplot2)\nlibrary(plotly)\n\nWarning: package 'plotly' was built under R version 4.3.3\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nhpi2016=read.csv(\"https://raw.githubusercontent.com/datageneration/datavisualization/master/data/hpi2016all.csv\")\n# Create ggplot\np &lt;- ggplot(hpi2016, aes(x = AverageLifeExpectancy, y = HappyPlanetIndex, color = Region, shape = Region, text = paste(\"Country:\", Country, \"&lt;br&gt;GDPPC:\", GDPPC))) +\n  geom_point(size = 1)  +\n  labs(title = \"Happy Planet Index vs. Life Expectancy\", x = \"Average Life Expectancy\", y = \"Happy Planet Index\") +\n  theme_bw() \n\n# Convert to ggplotly for interactivity\nggplotly(p, tooltip = \"text\") %&gt;% \n  layout(legend = list(x = 0.05, y = .98))\n\n\n\n\n\n\nHappy Planet Index data are presented here. This is to demo the story of the chart created using bokeh.\n\n\n\n\n\nWarning: package 'leaflet' was built under R version 4.3.3\n\n\n\n\n\n\n\nAn interactive map usiing leaflet or mapview can be used here. Instructions of using the map can be loaded here.\n\n\n\n\nlibrary(RColorBrewer)\nplot(pressure, pch=20, col = \"firebrick\")\n\n\n\n\n\n\n\n\n\nThis is a simple base plot.\n\n\n\n\nknitr::include_url(\"https://karlho.github.io/files/Rosling_animate.gif\", height = \"800\")\n\n\n\n\nExternal content can be loaded here: in this case, Hans Rosling’s famous chart.\n\n\n\n\nknitr::include_url(\"https://karlho.github.io/D3/lg_twclimate/index.html\", height = \"600\")\n\n\n\n\nYou can load your apps or project works here.\n\n\n\n\nlibrary(tidycensus)\n\nWarning: package 'tidycensus' was built under R version 4.3.3\n\noptions(tigris_use_cache = TRUE)\n\nlibrary(tmap)\n\nWarning: package 'tmap' was built under R version 4.3.3\n\n\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ndallas_income &lt;- get_acs(\n  geography = \"tract\",\n  variables = \"B19013_001\",\n  year = 2020,\n  state = \"TX\",\n  county = \"Dallas\",\n  geometry = TRUE\n)\n\nGetting data from the 2016-2020 5-year ACS\n\n\nWarning: • You have not set a Census API key. Users without a key are limited to 500\nqueries per day and may experience performance limitations.\nℹ For best results, get a Census API key at\nhttp://api.census.gov/data/key_signup.html and then supply the key to the\n`census_api_key()` function to use it throughout your tidycensus session.\nThis warning is displayed once per session.\n\nlibrary(mapview)\n\nWarning: package 'mapview' was built under R version 4.3.3\n\nmapview(dallas_income, zcol = \"estimate\")\n\n\n\n\n\n\nThis is created using Census data (Dallas ACS 2020) and tmap package.\n\n\n\n\nknitr::include_url(\"https://karlho.github.io/spatial/tmap_dallasincome.html\", height = \"800\")\n\n\n\n\nUpload the output file to GitHub and reference to file address."
  },
  {
    "objectID": "assignments/assignment8.html#dashboard-practice",
    "href": "assignments/assignment8.html#dashboard-practice",
    "title": "Final Project Storyboard: Team John Doe",
    "section": "",
    "text": "(Narrative in main window)\n\nThis project is about visualization of the public spending on saving environment.\n\n(Text in side window)\nPrerequisite: install.packages(c(“flexdashboard”,“rbokeh”,“leaflet”, “mapview”, “tidycensus”))\nThis storyboard delivers the final project product by exhibiting the final project in pages.\n\n\n\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'gapminder' was built under R version 4.3.3\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\n\n\n\n\n\n\n\n\nNarrative of Gapminder data.\n\n\n\n\nlibrary(ggplot2)\nlibrary(plotly)\n\nWarning: package 'plotly' was built under R version 4.3.3\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nhpi2016=read.csv(\"https://raw.githubusercontent.com/datageneration/datavisualization/master/data/hpi2016all.csv\")\n# Create ggplot\np &lt;- ggplot(hpi2016, aes(x = AverageLifeExpectancy, y = HappyPlanetIndex, color = Region, shape = Region, text = paste(\"Country:\", Country, \"&lt;br&gt;GDPPC:\", GDPPC))) +\n  geom_point(size = 1)  +\n  labs(title = \"Happy Planet Index vs. Life Expectancy\", x = \"Average Life Expectancy\", y = \"Happy Planet Index\") +\n  theme_bw() \n\n# Convert to ggplotly for interactivity\nggplotly(p, tooltip = \"text\") %&gt;% \n  layout(legend = list(x = 0.05, y = .98))\n\n\n\n\n\n\nHappy Planet Index data are presented here. This is to demo the story of the chart created using bokeh.\n\n\n\n\n\nWarning: package 'leaflet' was built under R version 4.3.3\n\n\n\n\n\n\n\nAn interactive map usiing leaflet or mapview can be used here. Instructions of using the map can be loaded here.\n\n\n\n\nlibrary(RColorBrewer)\nplot(pressure, pch=20, col = \"firebrick\")\n\n\n\n\n\n\n\n\n\nThis is a simple base plot.\n\n\n\n\nknitr::include_url(\"https://karlho.github.io/files/Rosling_animate.gif\", height = \"800\")\n\n\n\n\nExternal content can be loaded here: in this case, Hans Rosling’s famous chart.\n\n\n\n\nknitr::include_url(\"https://karlho.github.io/D3/lg_twclimate/index.html\", height = \"600\")\n\n\n\n\nYou can load your apps or project works here.\n\n\n\n\nlibrary(tidycensus)\n\nWarning: package 'tidycensus' was built under R version 4.3.3\n\noptions(tigris_use_cache = TRUE)\n\nlibrary(tmap)\n\nWarning: package 'tmap' was built under R version 4.3.3\n\n\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ndallas_income &lt;- get_acs(\n  geography = \"tract\",\n  variables = \"B19013_001\",\n  year = 2020,\n  state = \"TX\",\n  county = \"Dallas\",\n  geometry = TRUE\n)\n\nGetting data from the 2016-2020 5-year ACS\n\n\nWarning: • You have not set a Census API key. Users without a key are limited to 500\nqueries per day and may experience performance limitations.\nℹ For best results, get a Census API key at\nhttp://api.census.gov/data/key_signup.html and then supply the key to the\n`census_api_key()` function to use it throughout your tidycensus session.\nThis warning is displayed once per session.\n\nlibrary(mapview)\n\nWarning: package 'mapview' was built under R version 4.3.3\n\nmapview(dallas_income, zcol = \"estimate\")\n\n\n\n\n\n\nThis is created using Census data (Dallas ACS 2020) and tmap package.\n\n\n\n\nknitr::include_url(\"https://karlho.github.io/spatial/tmap_dallasincome.html\", height = \"800\")\n\n\n\n\nUpload the output file to GitHub and reference to file address."
  },
  {
    "objectID": "assignments/exercises.html#review-edward-tuftes-the-future-of-data-analysis",
    "href": "assignments/exercises.html#review-edward-tuftes-the-future-of-data-analysis",
    "title": "Exercises",
    "section": "",
    "text": "In his 2016 presentation, Edward Tufte discusses the evolution of data visualization, emphasizing the need for clarity, precision, and efficiency in presentations. He advocates for integrating statistical thinking with visual design to enhance understanding and decision-making. Tufte highlights the importance of data density in visualizations, using Google Maps as an example of effective complex data communication.\nTufte also addresses the replication crisis in research, citing significant studies to emphasize the need for honest and rigorous data analysis. He warns against manipulating data to fit narratives, suggesting that confirmatory data analysis should adhere to pre-specified methods like those used by the CDC.\nMoreover, Tufte encourages a hands-on approach to understanding data generation and its real-world implications. This method promotes a comprehensive understanding of data and its context, which is crucial for producing relevant and reliable visual representations.\nOverall, Tufte’s lecture serves as both a critical examination of current practices in data analysis and a guide to future innovations. His call for integrity in data visualization and analysis resonates strongly with anyone aspiring to enter the field, offering essential insights for conducting ethical and effective research."
  },
  {
    "objectID": "assignments/exercises.html#literate-programming",
    "href": "assignments/exercises.html#literate-programming",
    "title": "Exercises",
    "section": "2 Literate Programming",
    "text": "2 Literate Programming\nLiterate Programming, introduced by Donald Knuth in 1984, encourages programmers to integrate comprehensive documentation directly with their code. This method focuses on enhancing the readability of code, ensuring that it’s understandable to humans as well as executable by machines.\nKnuth advocated for a shift in perspective: programmers should prioritize explaining their logic to humans, not just instructing computers. This involves embedding code within a narrative that explains what the computer is supposed to do, making the codebase more accessible and easier to maintain.\nTools like R Markdown and Jupyter Notebooks facilitate this approach by allowing the integration of narrative text with executable code, which is particularly valuable in research for ensuring reproducibility and transparency."
  },
  {
    "objectID": "assignments/exercises.html#review-of-stephen-malinowskis-music-visualization",
    "href": "assignments/exercises.html#review-of-stephen-malinowskis-music-visualization",
    "title": "Exercises",
    "section": "3 Review of Stephen Malinowski’s Music Visualization",
    "text": "3 Review of Stephen Malinowski’s Music Visualization\nStephen Malinowski’s visualization of Bach’s compositions through his YouTube video is an intriguing exploration into the synthesis of visual arts and classical music. By employing a detailed mapping system where musical notes are linked to specific visual symbols, Malinowski enhances the auditory experience with corresponding visual cues, making the complexities of classical compositions more accessible and engaging.\nIn his video, Malinowski assigns different shapes to represent various musical elements, while colors shift to reflect changes in pitch and intensity. This method not only illustrates the music’s structure but also its emotional depth, allowing viewers to perceive subtle shifts in tone and rhythm visually. For instance, a transition to a minor key might be represented by cooler colors, guiding the viewer through the music’s emotive journey.\nThe size and motion of these shapes correspond directly to the dynamics and duration of the notes, effectively translating the music’s texture into a visual format. This innovative approach does more than just accompany the music; it opens up a new avenue for understanding and appreciating complex musical narratives without needing a formal background in music theory.\nMalinowski’s work is a compelling demonstration of how visual elements can transform our experience of music. The combination of auditory and visual stimuli not only makes classical music more approachable but also enriches the listening experience, offering a multi-sensory exploration of musical storytelling. His approach could serve as a valuable educational tool, offering a new perspective on music analysis and appreciation."
  },
  {
    "objectID": "assignments/exercises.html#big-data-analytics-pitfalls-and-overfitting",
    "href": "assignments/exercises.html#big-data-analytics-pitfalls-and-overfitting",
    "title": "Exercises",
    "section": "4 Big Data Analytics Pitfalls and Overfitting",
    "text": "4 Big Data Analytics Pitfalls and Overfitting\nNavigating through the vast seas of big data, I have come to recognize its immense potential and pitfalls. The allure of big data often leads to the assumption that sheer volume equates to veracity, a misconception famously critiqued through the failures of Google Flu Trends. This initiative aimed to predict flu outbreaks using search data but faltered, significantly overestimating flu cases. This example starkly illustrates that big data is not a panacea; it must be carefully curated and analyzed, blending traditional methodologies to enhance its reliability and validity.\nMoreover, my journey through data science has underscored the dangers of overfitting—tailoring models too closely to specific datasets. This practice, while initially seeming to improve accuracy, actually degrades the model’s applicability to new data. It’s a compelling reminder of the balance needed between model complexity and interpretability. Overparameterization further exacerbates this issue, introducing too many variables and making the model overly sensitive to minor data fluctuations.\nThese experiences have taught me the importance of skepticism and rigor in data analysis. As budding data scientists, we must strive to ensure our models not only fit the data but also reveal the underlying truths, maintaining a steadfast commitment to accuracy and generalizability."
  },
  {
    "objectID": "project/project.html#dashboard",
    "href": "project/project.html#dashboard",
    "title": "Project",
    "section": "3 Dashboard",
    "text": "3 Dashboard"
  },
  {
    "objectID": "project/project.html#project-proposal-presentation",
    "href": "project/project.html#project-proposal-presentation",
    "title": "Project",
    "section": "4 Project Proposal Presentation",
    "text": "4 Project Proposal Presentation"
  },
  {
    "objectID": "project/project.html#project-report",
    "href": "project/project.html#project-report",
    "title": "Project",
    "section": "2 Project Report",
    "text": "2 Project Report"
  },
  {
    "objectID": "project/project.html#project-proposal",
    "href": "project/project.html#project-proposal",
    "title": "Project",
    "section": "3 Project Proposal",
    "text": "3 Project Proposal"
  }
]